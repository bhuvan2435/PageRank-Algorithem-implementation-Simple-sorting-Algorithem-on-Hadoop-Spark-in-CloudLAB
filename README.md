
Steps to run the code--
Put pagerank.sh and pagerank-part3.py in the same directory
Assuming that the hadoop and spark are in the default directory as mentioned in HW manual the code should run
It will ask for input from the user, this input will be the dataset
Same procedure can be followed for both the dataset
The ouput will give us elapsed time for four tasks as mentioned in the HW manual. 
