
Put the hw1-spark.sh and the spark-part2.py in the same directory
Assuming that the hadoop and spark are in the default directory as mentioned in HW manual the code should run.
It will ask for 2 arguments one would be the input file and the other would be the output file.
Input file should be the dataset on which sorting need to be done.
Output file should be the .csv file which will contain the results.
